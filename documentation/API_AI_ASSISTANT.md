# ğŸ¤– AI Recipe Assistant API Documentation

## Overview

Chef AI este un asistent culinar inteligent cu **sistem Ã®n 3 niveluri**:

1. **ğŸ” Local (GRATUIT)** - CautÄƒ Ã®n reÈ›etele existente din comunitate
2. **ğŸ¦™ Llama (GRATUIT)** - GenereazÄƒ reÈ›ete cu AI local (Ollama/Llama 3.1)
3. **âœ¨ OpenAI (PREMIUM)** - Generare cu GPT-4 (opÈ›ional, necesitÄƒ API key)

### Flux de funcÈ›ionare:
```
User Message â†’ Parse Local â†’ Search Recipes â†’ Found? 
                                              â”œâ”€â”€ YES â†’ Return recommendations (FREE)
                                              â””â”€â”€ NO â†’ Generate with AI (Llama FREE / OpenAI PAID)
```

---

## API Endpoints

### Base URL
```
https://your-domain.com/api/v1/ai
```

### Headers necesare
```
Authorization: Bearer <jwt_token>
Content-Type: application/json
```

---

## 1. Chat cu AI Assistant

### `POST /api/v1/ai/chat`

Trimite un mesaj cÄƒtre AI È™i primeÈ™te rÄƒspunsul.

#### Request Body
```json
{
  "message": "Am pui, roÈ™ii È™i usturoi. Ce pot gÄƒti?",
  "provider": "local",
  "conversation_id": "optional-uuid"
}
```

#### Provider Options:
| Provider | Cost | Descriere |
|----------|------|-----------|
| `local` | Gratuit | CautÄƒ doar Ã®n reÈ›ete existente |
| `llama` | Gratuit | GenereazÄƒ cu Llama 3.1 (necesitÄƒ Ollama) |
| `openai` | PlÄƒtit | GenereazÄƒ cu GPT-4 (necesitÄƒ API key) |

#### Response - Recommendation (reÈ›ete gÄƒsite)
```json
{
  "success": true,
  "data": {
    "conversation_id": "uuid",
    "response": {
      "message": "ğŸ‰ Am gÄƒsit 3 reÈ›ete care se potrivesc...",
      "type": "recommendation",
      "ai_provider": "local",
      "recommended_recipe_id": 123,
      "alternatives": [124, 125],
      "matching_recipes": [
        {
          "id": 123,
          "title": "Pui cu roÈ™ii È™i usturoi",
          "match_percentage": 95,
          "matched_ingredients": ["pui", "roÈ™ii", "usturoi"],
          "missing_ingredients": ["ceapÄƒ"],
          "time_to_make": 45,
          "difficulty": 2,
          "likes_count": 156,
          "user": "chef_maria"
        }
      ]
    },
    "provider_used": "local",
    "timestamp": "2025-11-27T15:30:00Z"
  }
}
```

#### Response - No Match (oferÄƒ generare AI)
```json
{
  "success": true,
  "data": {
    "response": {
      "message": "ğŸ˜• Nu am gÄƒsit reÈ›ete Ã®n baza noastrÄƒ...",
      "type": "no_match",
      "ai_provider": "local",
      "ingredients": ["pui", "roÈ™ii", "usturoi"],
      "can_generate": true
    }
  }
}
```

#### Response - Generated Recipe (de la Llama/OpenAI)
```json
{
  "success": true,
  "data": {
    "response": {
      "message": "ğŸ³ Am creat o reÈ›etÄƒ specialÄƒ pentru tine!",
      "type": "generated_recipe",
      "ai_provider": "llama",
      "recipe": {
        "title": "Pui aromat cu roÈ™ii È™i usturoi",
        "description": "O reÈ›etÄƒ simplÄƒ È™i delicioasÄƒ...",
        "ingredients": "- 500g piept de pui\n- 4 roÈ™ii mari\n...",
        "preparation": "1. TÄƒiaÈ›i puiul...\n2. ÃncÄƒlziÈ›i uleiul...",
        "time_to_make": 30,
        "difficulty": 2,
        "healthiness": 4,
        "tips": "Pentru mai mult gust, marinaÈ›i 30 min"
      }
    }
  }
}
```

#### Response - Insufficient Ingredients
```json
{
  "success": true,
  "data": {
    "response": {
      "message": "ğŸ“ Ai doar 2 ingrediente...",
      "type": "insufficient_ingredients",
      "ai_provider": "local",
      "suggested_ingredients": ["ceapÄƒ", "ulei", "sare"],
      "possible_recipes_with_additions": ["Pui la tigaie", "SupÄƒ de pui"]
    }
  }
}
```

---

## 2. Lista Provideri Disponibili

### `GET /api/v1/ai/providers`

ReturneazÄƒ lista de provideri AI disponibili.

#### Response
```json
{
  "success": true,
  "data": {
    "providers": [
      {
        "id": "local",
        "name": "CÄƒutare LocalÄƒ",
        "description": "CautÄƒ Ã®n reÈ›etele existente",
        "available": true,
        "cost": "Gratuit",
        "icon": "ğŸ”"
      },
      {
        "id": "llama",
        "name": "Llama 3.1",
        "description": "GenereazÄƒ reÈ›ete cu AI local",
        "available": true,
        "cost": "Gratuit",
        "icon": "ğŸ¦™",
        "setup_required": false
      },
      {
        "id": "openai",
        "name": "OpenAI GPT-4",
        "description": "Generare premium",
        "available": false,
        "cost": "Premium",
        "icon": "âœ¨",
        "setup_required": true
      }
    ],
    "default": "local"
  }
}
```

---

## 3. Salvare ReÈ›etÄƒ GeneratÄƒ

### `POST /api/v1/ai/save_recipe`

SalveazÄƒ o reÈ›etÄƒ generatÄƒ de AI Ã®n profilul utilizatorului.

#### Request Body
```json
{
  "recipe": {
    "title": "Pui aromat cu roÈ™ii",
    "description": "O reÈ›etÄƒ delicioasÄƒ...",
    "ingredients": "- 500g pui\n- 4 roÈ™ii...",
    "preparation": "1. TÄƒiaÈ›i puiul...",
    "time_to_make": 30,
    "difficulty": 2,
    "healthiness": 4
  }
}
```

#### Success Response
```json
{
  "success": true,
  "data": {
    "message": "Recipe saved successfully",
    "recipe": {
      "id": 456,
      "title": "Pui aromat cu roÈ™ii",
      "created_at": "2025-11-27T15:35:00Z"
    }
  }
}
```

---

## Flutter Implementation

### Service Class

```dart
class AiAssistantService {
  final String baseUrl;
  final String authToken;

  AiAssistantService({required this.baseUrl, required this.authToken});

  /// Chat with AI - uses 3-tier system
  /// provider: "local" (free), "llama" (free), "openai" (paid)
  Future<Map<String, dynamic>> chat(
    String message, {
    String provider = 'local',
    String? conversationId,
  }) async {
    final response = await http.post(
      Uri.parse('$baseUrl/api/v1/ai/chat'),
      headers: {
        'Authorization': 'Bearer $authToken',
        'Content-Type': 'application/json',
      },
      body: jsonEncode({
        'message': message,
        'provider': provider,
        if (conversationId != null) 'conversation_id': conversationId,
      }),
    );

    if (response.statusCode == 200) {
      return jsonDecode(response.body);
    } else {
      throw Exception('AI chat failed: ${response.body}');
    }
  }

  /// Get available AI providers
  Future<List<Map<String, dynamic>>> getProviders() async {
    final response = await http.get(
      Uri.parse('$baseUrl/api/v1/ai/providers'),
      headers: {'Authorization': 'Bearer $authToken'},
    );

    if (response.statusCode == 200) {
      final data = jsonDecode(response.body);
      return List<Map<String, dynamic>>.from(data['data']['providers']);
    }
    return [];
  }

  /// Save AI-generated recipe
  Future<Map<String, dynamic>> saveRecipe(Map<String, dynamic> recipe) async {
    final response = await http.post(
      Uri.parse('$baseUrl/api/v1/ai/save_recipe'),
      headers: {
        'Authorization': 'Bearer $authToken',
        'Content-Type': 'application/json',
      },
      body: jsonEncode({'recipe': recipe}),
    );

    if (response.statusCode == 200 || response.statusCode == 201) {
      return jsonDecode(response.body);
    }
    throw Exception('Save failed: ${response.body}');
  }
}
```

### Usage Example

```dart
final aiService = AiAssistantService(
  baseUrl: 'https://api.recipy.com',
  authToken: userToken,
);

// Step 1: Try local search first (FREE)
var result = await aiService.chat(
  'Am pui, roÈ™ii È™i usturoi',
  provider: 'local',
);

if (result['data']['response']['type'] == 'no_match') {
  // Step 2: Generate with Llama (FREE)
  result = await aiService.chat(
    'Am pui, roÈ™ii È™i usturoi',
    provider: 'llama',
  );
}

// Display result
if (result['data']['response']['type'] == 'recommendation') {
  // Show matching recipes
  final recipes = result['data']['response']['matching_recipes'];
  // ...
} else if (result['data']['response']['type'] == 'generated_recipe') {
  // Show generated recipe
  final recipe = result['data']['response']['recipe'];
  // ...
}
```

---

## Response Types Summary

| Type | Provider | CÃ¢nd apare |
|------|----------|------------|
| `recommendation` | local | ReÈ›ete gÄƒsite Ã®n DB |
| `no_match` | local | Nu s-au gÄƒsit reÈ›ete |
| `generated_recipe` | llama/openai | ReÈ›etÄƒ generatÄƒ de AI |
| `insufficient_ingredients` | local | Prea puÈ›ine ingrediente (<3) |
| `need_clarification` | local | Nu s-au identificat ingrediente |
| `error` | any | Eroare la procesare |

---

## Setup Ollama (pentru Llama gratuit)

### Instalare Ollama
```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh
```

### DescarcÄƒ Llama 3.1
```bash
ollama pull llama3.1:8b
```

### PorneÈ™te serverul
```bash
ollama serve
```

### Configurare Ã®n .env
```env
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
```

---

## Costuri Estimate

| Provider | Cost per request | Recomandare |
|----------|-----------------|-------------|
| Local | $0 | âœ… FoloseÈ™te mereu primul |
| Llama | $0 (self-hosted) | âœ… Pentru generare gratuitÄƒ |
| OpenAI | ~$0.002 | âš ï¸ Doar cÃ¢nd e necesar |

**Strategie recomandatÄƒ:**
1. Ãntotdeauna cautÄƒ local mai Ã®ntÃ¢i
2. OferÄƒ Llama ca opÈ›iune de generare gratuitÄƒ
3. OpenAI doar pentru utilizatori premium sau cÃ¢nd Llama nu e disponibil
